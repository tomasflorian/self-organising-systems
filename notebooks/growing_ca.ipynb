{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Growing Neural Cellular Automata",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28S76DVlfCMZ"
      },
      "source": [
        "# Growing Neural Cellular Automata\n",
        "\n",
        "This notebook contains code to reproduce experiments and figures for the [\"Growing Neural Cellular Automata\"](http://distill.pub/2020/growing-ca) article.\n",
        "\n",
        "Copyright 2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5wi_r4gyzFr"
      },
      "source": [
        "#@title Imports and Notebook Utilities\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import os\n",
        "import io\n",
        "import PIL.Image, PIL.ImageDraw\n",
        "import base64\n",
        "import zipfile\n",
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pylab as pl\n",
        "import glob\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from IPython.display import Image, HTML, clear_output\n",
        "import tqdm\n",
        "\n",
        "import os\n",
        "os.environ['FFMPEG_BINARY'] = 'ffmpeg'\n",
        "import moviepy.editor as mvp\n",
        "from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter\n",
        "clear_output()\n",
        "\n",
        "def np2pil(a):\n",
        "  if a.dtype in [np.float32, np.float64]:\n",
        "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
        "  return PIL.Image.fromarray(a)\n",
        "\n",
        "def imwrite(f, a, fmt=None):\n",
        "  a = np.asarray(a)\n",
        "  if isinstance(f, str):\n",
        "    fmt = f.rsplit('.', 1)[-1].lower()\n",
        "    if fmt == 'jpg':\n",
        "      fmt = 'jpeg'\n",
        "    f = open(f, 'wb')\n",
        "  np2pil(a).save(f, fmt, quality=95)\n",
        "\n",
        "def imencode(a, fmt='jpeg'):\n",
        "  a = np.asarray(a)\n",
        "  if len(a.shape) == 3 and a.shape[-1] == 4:\n",
        "    fmt = 'png'\n",
        "  f = io.BytesIO()\n",
        "  imwrite(f, a, fmt)\n",
        "  return f.getvalue()\n",
        "\n",
        "def im2url(a, fmt='jpeg'):\n",
        "  encoded = imencode(a, fmt)\n",
        "  base64_byte_string = base64.b64encode(encoded).decode('ascii')\n",
        "  return 'data:image/' + fmt.upper() + ';base64,' + base64_byte_string\n",
        "\n",
        "def imshow(a, fmt='jpeg'):\n",
        "  display(Image(data=imencode(a, fmt)))\n",
        "\n",
        "def tile2d(a, w=None):\n",
        "  a = np.asarray(a)\n",
        "  if w is None:\n",
        "    w = int(np.ceil(np.sqrt(len(a))))\n",
        "  th, tw = a.shape[1:3]\n",
        "  pad = (w-len(a))%w\n",
        "  a = np.pad(a, [(0, pad)]+[(0, 0)]*(a.ndim-1), 'constant')\n",
        "  h = len(a)//w\n",
        "  a = a.reshape([h, w]+list(a.shape[1:]))\n",
        "  a = np.rollaxis(a, 2, 1).reshape([th*h, tw*w]+list(a.shape[4:]))\n",
        "  return a\n",
        "\n",
        "def zoom(img, scale=4):\n",
        "  img = np.repeat(img, scale, 0)\n",
        "  img = np.repeat(img, scale, 1)\n",
        "  return img\n",
        "\n",
        "class VideoWriter:\n",
        "  def __init__(self, filename, fps=30.0, **kw):\n",
        "    self.writer = None\n",
        "    self.params = dict(filename=filename, fps=fps, **kw)\n",
        "\n",
        "  def add(self, img):\n",
        "    img = np.asarray(img)\n",
        "    if self.writer is None:\n",
        "      h, w = img.shape[:2]\n",
        "      self.writer = FFMPEG_VideoWriter(size=(w, h), **self.params)\n",
        "    if img.dtype in [np.float32, np.float64]:\n",
        "      img = np.uint8(img.clip(0, 1)*255)\n",
        "    if len(img.shape) == 2:\n",
        "      img = np.repeat(img[..., None], 3, -1)\n",
        "    self.writer.write_frame(img)\n",
        "\n",
        "  def close(self):\n",
        "    if self.writer:\n",
        "      self.writer.close()\n",
        "\n",
        "  def __enter__(self):\n",
        "    return self\n",
        "\n",
        "  def __exit__(self, *kw):\n",
        "    self.close()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR6I1JONmWBb"
      },
      "source": [
        "#@title Cellular Automata Parameters\n",
        "CHANNEL_N = 16        # Number of CA state channels\n",
        "TARGET_PADDING = 16   # Number of pixels used to pad the target image border\n",
        "TARGET_SIZE = 40\n",
        "BATCH_SIZE = 8\n",
        "POOL_SIZE = 1024\n",
        "CELL_FIRE_RATE = 0.5\n",
        "\n",
        "TARGET_EMOJI = \"🦎\" #@param {type:\"string\"}\n",
        "\n",
        "EXPERIMENT_TYPE = \"Regenerating\" #@param [\"Growing\", \"Persistent\", \"Regenerating\"]\n",
        "EXPERIMENT_MAP = {\"Growing\":0, \"Persistent\":1, \"Regenerating\":2}\n",
        "EXPERIMENT_N = EXPERIMENT_MAP[EXPERIMENT_TYPE]\n",
        "\n",
        "USE_PATTERN_POOL = [0, 1, 1][EXPERIMENT_N]\n",
        "DAMAGE_N = [0, 0, 3][EXPERIMENT_N]  # Number of patterns to damage in a batch"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCbPFbI_zosW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "19ad5ef2-0a16-48f9-8d9a-5876c0d2c1f0"
      },
      "source": [
        "#@title CA Model and Utilities\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "def load_image(url, max_size=TARGET_SIZE):\n",
        "  r = requests.get(url)\n",
        "  img = PIL.Image.open(io.BytesIO(r.content))\n",
        "  img.thumbnail((max_size, max_size))\n",
        "  img = np.float32(img)/255.0\n",
        "  # premultiply RGB by Alpha\n",
        "  img[..., :3] *= img[..., 3:]\n",
        "  return img\n",
        "\n",
        "def load_emoji(emoji):\n",
        "  code = hex(ord(emoji))[2:].lower()\n",
        "  url = 'https://github.com/googlefonts/noto-emoji/blob/main/png/128/emoji_u%s.png?raw=true'%code\n",
        "  return load_image(url)\n",
        "\n",
        "\n",
        "def to_rgba(x):\n",
        "  return x[..., :4]\n",
        "\n",
        "def to_alpha(x):\n",
        "  return tf.clip_by_value(x[..., 3:4], 0.0, 1.0)\n",
        "\n",
        "def to_rgb(x):\n",
        "  # assume rgb premultiplied by alpha\n",
        "  rgb, a = x[..., :3], to_alpha(x)\n",
        "  return 1.0-a+rgb\n",
        "\n",
        "def get_living_mask(x):\n",
        "  alpha = x[:, :, :, 3:4]\n",
        "  return tf.nn.max_pool2d(alpha, 3, [1, 1, 1, 1], 'SAME') > 0.1\n",
        "\n",
        "def make_seed(size, n=1):\n",
        "  x = np.zeros([n, size, size, CHANNEL_N], np.float32)\n",
        "  x[:, size//2, size//2, 3:] = 1.0\n",
        "  return x\n",
        "\n",
        "\n",
        "class CAModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, channel_n=CHANNEL_N, fire_rate=CELL_FIRE_RATE):\n",
        "    super().__init__()\n",
        "    self.channel_n = channel_n\n",
        "    self.fire_rate = fire_rate\n",
        "\n",
        "    self.dmodel = tf.keras.Sequential([\n",
        "          Conv2D(128, 1, activation=tf.nn.relu),\n",
        "          Conv2D(self.channel_n, 1, activation=None,\n",
        "              kernel_initializer=tf.zeros_initializer),\n",
        "    ])\n",
        "\n",
        "    self(tf.zeros([1, 3, 3, channel_n]))  # dummy call to build the model\n",
        "\n",
        "  @tf.function\n",
        "  def perceive(self, x, angle=0.0):\n",
        "    identify = np.float32([0, 1, 0])\n",
        "    identify = np.outer(identify, identify)\n",
        "    dx = np.outer([1, 2, 1], [-1, 0, 1]) / 8.0  # Sobel filter\n",
        "    dy = dx.T\n",
        "    c, s = tf.cos(angle), tf.sin(angle)\n",
        "    kernel = tf.stack([identify, c*dx-s*dy, s*dx+c*dy], -1)[:, :, None, :]\n",
        "    kernel = tf.repeat(kernel, self.channel_n, 2)\n",
        "    y = tf.nn.depthwise_conv2d(x, kernel, [1, 1, 1, 1], 'SAME')\n",
        "    return y\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, x, fire_rate=None, angle=0.0, step_size=1.0):\n",
        "    pre_life_mask = get_living_mask(x)\n",
        "\n",
        "    y = self.perceive(x, angle)\n",
        "    dx = self.dmodel(y)*step_size\n",
        "    if fire_rate is None:\n",
        "      fire_rate = self.fire_rate\n",
        "    update_mask = tf.random.uniform(tf.shape(x[:, :, :, :1])) <= fire_rate\n",
        "    x += dx * tf.cast(update_mask, tf.float32)\n",
        "\n",
        "    post_life_mask = get_living_mask(x)\n",
        "    life_mask = pre_life_mask & post_life_mask\n",
        "    return x * tf.cast(life_mask, tf.float32)\n",
        "\n",
        "\n",
        "CAModel().dmodel.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m6,272\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │         \u001b[38;5;34m2,064\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,272</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,336\u001b[0m (32.56 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,336</span> (32.56 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,336\u001b[0m (32.56 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,336</span> (32.56 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDX5HL7VLd0z"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeWf6HeTe8kM"
      },
      "source": [
        "#@title Train Utilities (SamplePool, Model Export, Damage)\n",
        "from google.protobuf.json_format import MessageToDict\n",
        "from tensorflow.python.framework import convert_to_constants\n",
        "\n",
        "class SamplePool:\n",
        "  def __init__(self, *, _parent=None, _parent_idx=None, **slots):\n",
        "    self._parent = _parent\n",
        "    self._parent_idx = _parent_idx\n",
        "    self._slot_names = slots.keys()\n",
        "    self._size = None\n",
        "    for k, v in slots.items():\n",
        "      if self._size is None:\n",
        "        self._size = len(v)\n",
        "      assert self._size == len(v)\n",
        "      setattr(self, k, np.asarray(v))\n",
        "\n",
        "  def sample(self, n):\n",
        "    idx = np.random.choice(self._size, n, False)\n",
        "    batch = {k: getattr(self, k)[idx] for k in self._slot_names}\n",
        "    batch = SamplePool(**batch, _parent=self, _parent_idx=idx)\n",
        "    return batch\n",
        "\n",
        "  def commit(self):\n",
        "    for k in self._slot_names:\n",
        "      getattr(self._parent, k)[self._parent_idx] = getattr(self, k)\n",
        "\n",
        "@tf.function\n",
        "def make_circle_masks(n, h, w):\n",
        "  x = tf.linspace(-1.0, 1.0, w)[None, None, :]\n",
        "  y = tf.linspace(-1.0, 1.0, h)[None, :, None]\n",
        "  center = tf.random.uniform([2, n, 1, 1], -0.5, 0.5)\n",
        "  r = tf.random.uniform([n, 1, 1], 0.1, 0.4)\n",
        "  x, y = (x-center[0])/r, (y-center[1])/r\n",
        "  mask = tf.cast(x*x+y*y < 1.0, tf.float32)\n",
        "  return mask\n",
        "\n",
        "def export_model(ca, base_fn):\n",
        "  ca.save_weights(base_fn)\n",
        "\n",
        "  cf = ca.call.get_concrete_function(\n",
        "      x=tf.TensorSpec([None, None, None, CHANNEL_N]),\n",
        "      fire_rate=tf.constant(0.5),\n",
        "      angle=tf.constant(0.0),\n",
        "      step_size=tf.constant(1.0))\n",
        "  cf = convert_to_constants.convert_variables_to_constants_v2(cf)\n",
        "  graph_def = cf.graph.as_graph_def()\n",
        "  graph_json = MessageToDict(graph_def)\n",
        "  graph_json['versions'] = dict(producer='1.14', minConsumer='1.14')\n",
        "  model_json = {\n",
        "      'format': 'graph-model',\n",
        "      'modelTopology': graph_json,\n",
        "      'weightsManifest': [],\n",
        "  }\n",
        "  with open(base_fn+'.json', 'w') as f:\n",
        "    json.dump(model_json, f)\n",
        "\n",
        "def generate_pool_figures(pool, step_i):\n",
        "  tiled_pool = tile2d(to_rgb(pool.x[:49]))\n",
        "  fade = np.linspace(1.0, 0.0, 72)\n",
        "  ones = np.ones(72)\n",
        "  tiled_pool[:, :72] += (-tiled_pool[:, :72] + ones[None, :, None]) * fade[None, :, None]\n",
        "  tiled_pool[:, -72:] += (-tiled_pool[:, -72:] + ones[None, :, None]) * fade[None, ::-1, None]\n",
        "  tiled_pool[:72, :] += (-tiled_pool[:72, :] + ones[:, None, None]) * fade[:, None, None]\n",
        "  tiled_pool[-72:, :] += (-tiled_pool[-72:, :] + ones[:, None, None]) * fade[::-1, None, None]\n",
        "  imwrite('train_log/%04d_pool.jpg'%step_i, tiled_pool)\n",
        "\n",
        "def visualize_batch(x0, x, step_i):\n",
        "  vis0 = np.hstack(to_rgb(x0).numpy())\n",
        "  vis1 = np.hstack(to_rgb(x).numpy())\n",
        "  vis = np.vstack([vis0, vis1])\n",
        "  imwrite('train_log/batches_%04d.jpg'%step_i, vis)\n",
        "  print('batch (before/after):')\n",
        "  imshow(vis)\n",
        "\n",
        "def plot_loss(loss_log):\n",
        "  pl.figure(figsize=(10, 4))\n",
        "  pl.title('Loss history (log10)')\n",
        "  pl.plot(np.log10(loss_log), '.', alpha=0.1)\n",
        "  pl.show()\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKlA50h0jlvl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "bcadd05a-2cba-4183-a989-24c7f206fb24"
      },
      "source": [
        "#@title Choose Target Image { vertical-output: true}\n",
        "#url = 'https://github.com/google-research/self-organising-systems/blob/master/assets/growing_ca/planaria2_48.png?raw=true'\n",
        "#target_img = load_image(url, 48)\n",
        "\n",
        "target_img = load_emoji(TARGET_EMOJI)\n",
        "imshow(zoom(to_rgb(target_img), 2), fmt='png')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak5rBmbxmHV7"
      },
      "source": [
        "#@title Initialize Training { vertical-output: true}\n",
        "\n",
        "p = TARGET_PADDING\n",
        "pad_target = tf.pad(target_img, [(p, p), (p, p), (0, 0)])\n",
        "h, w = pad_target.shape[:2]\n",
        "seed = np.zeros([h, w, CHANNEL_N], np.float32)\n",
        "seed[h//2, w//2, 3:] = 1.0\n",
        "\n",
        "def loss_f(x):\n",
        "  return tf.reduce_mean(tf.square(to_rgba(x)-pad_target), [-2, -3, -1])\n",
        "\n",
        "ca = CAModel()\n",
        "\n",
        "loss_log = []\n",
        "\n",
        "lr = 2e-3\n",
        "lr_sched = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "    [2000], [lr, lr*0.1])\n",
        "trainer = tf.keras.optimizers.Adam(lr_sched)\n",
        "\n",
        "loss0 = loss_f(seed).numpy()\n",
        "pool = SamplePool(x=np.repeat(seed[None, ...], POOL_SIZE, 0))\n",
        "\n",
        "!mkdir -p train_log && rm -f train_log/*"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzP_vDchq0d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "7aa82254-6902-4a01-9bb5-c29685f2ada7"
      },
      "source": [
        "#@title Training Loop {vertical-output: true}\n",
        "\n",
        "@tf.function\n",
        "def train_step(x):\n",
        "  iter_n = tf.random.uniform([], 64, 96, tf.int32)\n",
        "  with tf.GradientTape() as g:\n",
        "    for i in tf.range(iter_n):\n",
        "      x = ca(x)\n",
        "    loss = tf.reduce_mean(loss_f(x))\n",
        "  grads = g.gradient(loss, ca.weights)\n",
        "  grads = [g/(tf.norm(g)+1e-8) for g in grads]\n",
        "  trainer.apply_gradients(zip(grads, ca.weights))\n",
        "  return x, loss\n",
        "\n",
        "for i in range(8000+1):\n",
        "  if USE_PATTERN_POOL:\n",
        "    batch = pool.sample(BATCH_SIZE)\n",
        "    x0 = batch.x\n",
        "    loss_rank = loss_f(x0).numpy().argsort()[::-1]\n",
        "    x0 = x0[loss_rank]\n",
        "    x0[:1] = seed\n",
        "    if DAMAGE_N:\n",
        "      damage = 1.0-make_circle_masks(DAMAGE_N, h, w).numpy()[..., None]\n",
        "      x0[-DAMAGE_N:] *= damage\n",
        "  else:\n",
        "    x0 = np.repeat(seed[None, ...], BATCH_SIZE, 0)\n",
        "\n",
        "  x, loss = train_step(x0)\n",
        "\n",
        "  if USE_PATTERN_POOL:\n",
        "    batch.x[:] = x\n",
        "    batch.commit()\n",
        "\n",
        "  step_i = len(loss_log)\n",
        "  loss_log.append(loss.numpy())\n",
        "\n",
        "  if step_i%10 == 0:\n",
        "    generate_pool_figures(pool, step_i)\n",
        "  if step_i%100 == 0:\n",
        "    clear_output()\n",
        "    visualize_batch(x0, x, step_i)\n",
        "    plot_loss(loss_log)\n",
        "    export_model(ca, 'train_log/%04d.weights.h5'%step_i)\n",
        "\n",
        "  print('\\r step: %d, log10(loss): %.3f'%(len(loss_log), np.log10(loss)), end='')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch (before/after):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " step: 42, log10(loss): -1.412"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2829191864.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mUSE_PATTERN_POOL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mstep_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2539483379.py\u001b[0m in \u001b[0;36mcommit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slot_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAscSKkRaFwp"
      },
      "source": [
        "# Figures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqvkfl9W4ODI"
      },
      "source": [
        "#@title Training Progress (Checkpoints)\n",
        "\n",
        "models = []\n",
        "for i in [100, 500, 1000, 4000]:\n",
        "  ca = CAModel()\n",
        "  ca.load_weights('train_log/%04d'%i)\n",
        "  models.append(ca)\n",
        "\n",
        "out_fn = 'train_steps_damage_%d.mp4'%DAMAGE_N\n",
        "x = np.zeros([len(models), 72, 72, CHANNEL_N], np.float32)\n",
        "x[..., 36, 36, 3:] = 1.0\n",
        "with VideoWriter(out_fn) as vid:\n",
        "  for i in tqdm.trange(500):\n",
        "    vis = np.hstack(to_rgb(x))\n",
        "    vid.add(zoom(vis, 2))\n",
        "    for ca, xk in zip(models, x):\n",
        "      xk[:] = ca(xk[None,...])[0]\n",
        "mvp.ipython_display(out_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeXZKb5v2gxj"
      },
      "source": [
        "#@title Training Progress (Batches)\n",
        "frames = sorted(glob.glob('train_log/batches_*.jpg'))\n",
        "mvp.ImageSequenceClip(frames, fps=10.0).write_videofile('batches.mp4')\n",
        "mvp.ipython_display('batches.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4JAbAJf6Alw"
      },
      "source": [
        "#@title Pool Contents\n",
        "frames = sorted(glob.glob('train_log/*_pool.jpg'))[:80]\n",
        "mvp.ImageSequenceClip(frames, fps=20.0).write_videofile('pool.mp4')\n",
        "mvp.ipython_display('pool.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyxeGm6dJX8D"
      },
      "source": [
        "## Pretrained Models and Figures\n",
        "\n",
        "Please run the cell below to download pretrained models that are used to generate the subsequent figures. The figures generated after this are generated using the pretrained CAs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiGl7S0E6-OA"
      },
      "source": [
        "!wget -O models.zip 'https://github.com/google-research/self-organising-systems/blob/master/assets/growing_ca/models.zip?raw=true'\n",
        "!unzip -oq models.zip\n",
        "\n",
        "EMOJI = '🦎😀💥👁🐠🦋🐞🕸🥨🎄'\n",
        "\n",
        "def get_model(emoji='🦋', fire_rate=0.5, use_pool=1, damage_n=3, run=0,\n",
        "              prefix='models/', output='model'):\n",
        "  path = prefix\n",
        "  assert fire_rate in [0.5, 1.0]\n",
        "  if fire_rate==0.5:\n",
        "    path += 'use_sample_pool_%d damage_n_%d '%(use_pool, damage_n)\n",
        "  elif fire_rate==1.0:\n",
        "    path += 'fire_rate_1.0 '\n",
        "  code = hex(ord(emoji))[2:].upper()\n",
        "  path += 'target_emoji_%s run_index_%d/08000'%(code, run)\n",
        "  assert output in ['model', 'json']\n",
        "  if output == 'model':\n",
        "    ca = CAModel(channel_n=16, fire_rate=fire_rate)\n",
        "    ca.load_weights(path)\n",
        "    return ca\n",
        "  elif output == 'json':\n",
        "    return open(path+'.json', 'r').read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyMms2wKwX9x"
      },
      "source": [
        "atlas = np.hstack([load_emoji(e) for e in EMOJI])\n",
        "imshow(atlas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqgtL5VpLEeL"
      },
      "source": [
        "#@title Teaser\n",
        "models = [get_model(emoji, run=1) for emoji in EMOJI]\n",
        "\n",
        "with VideoWriter('teaser.mp4') as vid:\n",
        "  x = np.zeros([len(EMOJI), 64, 64, CHANNEL_N], np.float32)\n",
        "  # grow\n",
        "  for i in tqdm.trange(200):\n",
        "    k = i//20\n",
        "    if i%20==0 and k<len(EMOJI):\n",
        "      x[k, 32, 32, 3:] = 1.0\n",
        "    vid.add(zoom(tile2d(to_rgb(x), 5), 2))\n",
        "    for ca, xk in zip(models, x):\n",
        "      xk[:] = ca(xk[None,...])[0]\n",
        "  # damage\n",
        "  mask = PIL.Image.new('L', (64*5, 64*2))\n",
        "  draw = PIL.ImageDraw.Draw(mask)\n",
        "  for i in tqdm.trange(400):\n",
        "    cx, r = i*3-20, 6\n",
        "    y1, y2 = 32+np.sin(i/5+np.pi)*8, 32+64+np.sin(i/5)*8\n",
        "    draw.rectangle((0, 0, 64*5, 64*2), fill=0)\n",
        "    draw.ellipse((cx-r, y1-r, cx+r, y1+r), fill=255)\n",
        "    draw.ellipse((cx-r, y2-r, cx+r, y2+r), fill=255)\n",
        "    x *= 1.0-(np.float32(mask).reshape(2, 64, 5, 64)\n",
        "        .transpose([0, 2, 1, 3]).reshape(10, 64, 64, 1))/255.0\n",
        "    if i<200 or i%2 == 0:\n",
        "      vid.add(zoom(tile2d(to_rgb(x), 5), 2))\n",
        "    for ca, xk in zip(models, x):\n",
        "      xk[:] = ca(xk[None,...])[0]\n",
        "  # fade out\n",
        "  last = zoom(tile2d(to_rgb(x), 5), 2)\n",
        "  for t in np.linspace(0, 1, 30):\n",
        "    vid.add(last*(1.0-t)+t)\n",
        "\n",
        "mvp.ipython_display('teaser.mp4', loop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O4tzfe-GRJ7"
      },
      "source": [
        "#@title Unstable Patterns\n",
        "!wget -O slider.png 'https://github.com/google-research/self-organising-systems/raw/master/assets/growing_ca/slider.png?raw=true'\n",
        "\n",
        "import PIL.ImageFont\n",
        "from matplotlib import font_manager as fm\n",
        "font_fn = fm.findfont(fm.FontProperties())\n",
        "font = PIL.ImageFont.truetype(font_fn, 20)\n",
        "\n",
        "models = [get_model(ch, use_pool=0, damage_n=0) for ch in EMOJI]\n",
        "fn = 'unstable.mp4'\n",
        "with VideoWriter(fn) as vid:\n",
        "  x = np.zeros([len(EMOJI), 64, 64, CHANNEL_N], np.float32)\n",
        "  x[:, 32, 32, 3:] = 1.0\n",
        "  # grow\n",
        "  slider = PIL.Image.open(\"slider.png\")\n",
        "  for i in tqdm.trange(1000):\n",
        "    if i<200 or i%5 == 0:\n",
        "      vis = zoom(tile2d(to_rgb(x), 5), 4).clip(0, 1)\n",
        "      vis_extended = np.concatenate((vis, np.ones((164, vis.shape[1], 3))), axis=0)\n",
        "      im = np.uint8(vis_extended*255)\n",
        "      im = PIL.Image.fromarray(im)\n",
        "      im.paste(slider, box=(20, vis.shape[0]+20))\n",
        "      draw = PIL.ImageDraw.Draw(im)\n",
        "      p_x = (14 + (610/1000)*i)*2.0\n",
        "      draw.rectangle([p_x, vis.shape[0]+20+55, p_x+10, vis.shape[0]+20+82], fill=\"#434343bd\")\n",
        "      vid.add(np.uint8(im))\n",
        "    for ca, xk in zip(models, x):\n",
        "      xk[:] = ca(xk[None,...])[0]\n",
        "  # fade out\n",
        "  for t in np.linspace(0, 1, 30):\n",
        "    vid.add(vis_extended*(1.0-t)+t)\n",
        "\n",
        "mvp.ipython_display(fn, loop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CVR9MeYnjuY"
      },
      "source": [
        "#@title Rotation\n",
        "row_size = 4\n",
        "models_of_interest = [\"🦋\",\"🦎\",\"🐠\",\"😀\"]\n",
        "num_images = 16\n",
        "imgs = []\n",
        "start_angle = np.random.randint(13, 76)\n",
        "\n",
        "for i in np.arange(num_images):\n",
        "  ang = start_angle + i * np.random.randint(36, 111)\n",
        "  ang = ang/360.0 * 2 * np.pi\n",
        "  if i % row_size == 0:\n",
        "    ca = get_model(models_of_interest[i // row_size])\n",
        "  x = np.zeros([1, 56, 56, CHANNEL_N], np.float32)\n",
        "  x[:, 28, 28, 3:] = 1.0\n",
        "  for i in range(500):\n",
        "    ang = tf.constant(ang, tf.float32)\n",
        "    x = ca(x, angle=ang)\n",
        "  imgs.append(to_rgb(x)[0])\n",
        "# Assumes the result is a multiple of row_size\n",
        "assert len(imgs) % row_size == 0\n",
        "imgs = zip(*(iter(imgs),) * row_size)\n",
        "\n",
        "imgs_arr = np.concatenate([np.hstack(im_row) for im_row in imgs])\n",
        "vis = zoom(imgs_arr, 4)\n",
        "\n",
        "imshow(vis, fmt='png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5JRLGxX1dnX"
      },
      "source": [
        "#@title Regeneration (trained without damage)\n",
        "models = [get_model(ch, damage_n=0) for ch in '😀🦋🦎']\n",
        "with VideoWriter('regen1.mp4') as vid:\n",
        "  x = np.zeros([len(models), 5, 56, 56, CHANNEL_N], np.float32)\n",
        "  cx, cy = 28, 28\n",
        "  x[:, :, cy, cx, 3:] = 1.0\n",
        "  for i in tqdm.trange(2000):\n",
        "    if i == 200:\n",
        "      x[:, 0, cy:] = x[:, 1, :cy] = 0\n",
        "      x[:, 2, :, cx:] = x[:, 3, :, :cx] = 0\n",
        "      x[:, 4, cy-8:cy+8, cx-8:cx+8] = 0\n",
        "    vis = to_rgb(x)\n",
        "    vis = np.vstack([np.hstack(row) for row in vis])\n",
        "    vis = zoom(vis, 2)\n",
        "    if (i < 400 and i%2==0) or i%8 == 0:\n",
        "      vid.add(vis)\n",
        "    if i == 200:\n",
        "      for _ in range(29):\n",
        "        vid.add(vis)\n",
        "    for ca, row in zip(models, x):\n",
        "      row[:] = ca(row)\n",
        "\n",
        "mvp.ipython_display('regen1.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDzJM69u4_8p"
      },
      "source": [
        "#@title Regeneration (trained with damage)\n",
        "models = [get_model(ch, damage_n=3) for ch in '😀🦋🦎']\n",
        "with VideoWriter('regen2.mp4') as vid:\n",
        "  x = np.zeros([len(models), 5, 56, 56, CHANNEL_N], np.float32)\n",
        "  cx, cy = 28, 28\n",
        "  x[:, :, cy, cx, 3:] = 1.0\n",
        "  for i in tqdm.trange(2000):\n",
        "    if i == 200:\n",
        "      x[:, 0, cy:] = x[:, 1, :cy] = 0\n",
        "      x[:, 2, :, cx:] = x[:, 3, :, :cx] = 0\n",
        "      x[:, 4, cy-8:cy+8, cx-8:cx+8] = 0\n",
        "    vis = to_rgb(x)\n",
        "    vis = np.vstack([np.hstack(row) for row in vis])\n",
        "    vis = zoom(vis, 2)\n",
        "    if (i < 400 and i%2==0) or i%8 == 0:\n",
        "      vid.add(vis)\n",
        "    if i == 200:\n",
        "      for _ in range(29):\n",
        "        vid.add(vis)\n",
        "    for ca, row in zip(models, x):\n",
        "      row[:] = ca(row)\n",
        "\n",
        "mvp.ipython_display('regen2.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ1u2MqFy7Ni"
      },
      "source": [
        "#@title Planarian\n",
        "!wget -O planarian.zip 'https://github.com/google-research/self-organising-systems/blob/master/assets/growing_ca/planarian.zip?raw=true'\n",
        "!unzip -oq planarian.zip -d planarian\n",
        "\n",
        "ca = CAModel()\n",
        "ca.load_weights('planarian/train_log/8000')\n",
        "\n",
        "x = np.zeros([1, 64, 96, CHANNEL_N], np.float32)\n",
        "x[:, 32, 48, 3:] = 1.0\n",
        "with VideoWriter('planarian.mp4', 30.0) as vid:\n",
        "  for i in range(400):\n",
        "    vid.add(zoom(to_rgb(x[0])))\n",
        "    x = ca(x, angle=np.pi/2.0)\n",
        "    if i==150:\n",
        "      x = x.numpy()\n",
        "      for k in range(24):\n",
        "        x[:,:24] = np.roll(x[:,:24], 1, 2)\n",
        "        x[:,-24:] = np.roll(x[:,-24:], -1, 2)\n",
        "        vid.add(zoom(to_rgb(x[0])))\n",
        "      for k in range(20):\n",
        "        vid.add(zoom(to_rgb(x[0])))\n",
        "\n",
        "mvp.ipython_display('planarian.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M-oDuhea7bR"
      },
      "source": [
        "# Interactive Demos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7ypa-b7_fTn"
      },
      "source": [
        "#@title TensorFlow.js Demo {run:\"auto\", vertical-output: true}\n",
        "#@markdown Select \"CHECKPOINT\" model to load the checkpoint created by running cells from the \"Training\" section of this notebook\n",
        "import IPython.display\n",
        "\n",
        "model = \"CHECKPOINT\"  #@param ['CHECKPOINT', '😀 1F600', '💥 1F4A5', '👁 1F441', '🦎 1F98E', '🐠 1F420', '🦋 1F98B', '🐞 1F41E', '🕸 1F578', '🥨 1F968', '🎄 1F384']\n",
        "model_type = '3 regenerating'  #@param ['1 naive', '2 persistent', '3 regenerating']\n",
        "\n",
        "#@markdown Shift-click to seed the pattern\n",
        "\n",
        "if model != 'CHECKPOINT':\n",
        "  code = model.split(' ')[1]\n",
        "  emoji = chr(int(code, 16))\n",
        "  experiment_i = int(model_type.split()[0])-1\n",
        "  use_pool = (0, 1, 1)[experiment_i]\n",
        "  damage_n = (0, 0, 3)[experiment_i]\n",
        "  model_str = get_model(emoji, use_pool=use_pool, damage_n=damage_n, output='json')\n",
        "else:\n",
        "  last_checkpoint_fn = sorted(glob.glob('train_log/*.json'))[-1]\n",
        "  model_str = open(last_checkpoint_fn).read()\n",
        "\n",
        "data_js = '''\n",
        "  window.GRAPH_URL = URL.createObjectURL(new Blob([`%s`], {type: 'application/json'}));\n",
        "'''%(model_str)\n",
        "\n",
        "display(IPython.display.Javascript(data_js))\n",
        "\n",
        "\n",
        "IPython.display.HTML('''\n",
        "<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@2.3.0/dist/tf.min.js\"></script>\n",
        "\n",
        "<canvas id='canvas' style=\"border: 1px solid black; image-rendering: pixelated;\"></canvas>\n",
        "\n",
        "<script>\n",
        "  \"use strict\";\n",
        "\n",
        "  const sleep = (ms)=>new Promise(resolve => setTimeout(resolve, ms));\n",
        "\n",
        "  const parseConsts = model_graph=>{\n",
        "    const dtypes = {'DT_INT32':['int32', 'intVal', Int32Array],\n",
        "                    'DT_FLOAT':['float32', 'floatVal', Float32Array]};\n",
        "\n",
        "    const consts = {};\n",
        "    model_graph.modelTopology.node.filter(n=>n.op=='Const').forEach((node=>{\n",
        "      const v = node.attr.value.tensor;\n",
        "      const [dtype, field, arrayType] = dtypes[v.dtype];\n",
        "      if (!v.tensorShape.dim) {\n",
        "        consts[node.name] = [tf.scalar(v[field][0], dtype)];\n",
        "      } else {\n",
        "        // if there is a 0-length dimension, the exported graph json lacks \"size\"\n",
        "        const shape = v.tensorShape.dim.map(d=>(!d.size) ? 0 : parseInt(d.size));\n",
        "        let arr;\n",
        "        if (v.tensorContent) {\n",
        "          const data = atob(v.tensorContent);\n",
        "          const buf = new Uint8Array(data.length);\n",
        "          for (var i=0; i<data.length; ++i) {\n",
        "            buf[i] = data.charCodeAt(i);\n",
        "          }\n",
        "          arr = new arrayType(buf.buffer);\n",
        "        } else {\n",
        "          const size = shape.reduce((a, b)=>a*b);\n",
        "          arr = new arrayType(size);\n",
        "          if (size) {\n",
        "            arr.fill(v[field][0]);\n",
        "          }\n",
        "        }\n",
        "        consts[node.name] = [tf.tensor(arr, shape, dtype)];\n",
        "      }\n",
        "    }));\n",
        "    return consts;\n",
        "  }\n",
        "\n",
        "  const run = async ()=>{\n",
        "    const r = await fetch(GRAPH_URL);\n",
        "    const consts = parseConsts(await r.json());\n",
        "\n",
        "    const model = await tf.loadGraphModel(GRAPH_URL);\n",
        "    Object.assign(model.weights, consts);\n",
        "\n",
        "    let seed = new Array(16).fill(0).map((x, i)=>i<3?0:1);\n",
        "    seed = tf.tensor(seed, [1, 1, 1, 16]);\n",
        "\n",
        "    const D = 96;\n",
        "    const initState = tf.tidy(()=>{\n",
        "      const D2 = D/2;\n",
        "      const a = seed.pad([[0, 0], [D2-1, D2], [D2-1, D2], [0,0]]);\n",
        "      return a;\n",
        "    });\n",
        "\n",
        "    const state = tf.variable(initState);\n",
        "    const [_, h, w, ch] = state.shape;\n",
        "\n",
        "    const damage = (x, y, r)=>{\n",
        "      tf.tidy(()=>{\n",
        "        const rx = tf.range(0, w).sub(x).div(r).square().expandDims(0);\n",
        "        const ry = tf.range(0, h).sub(y).div(r).square().expandDims(1);\n",
        "        const mask = rx.add(ry).greater(1.0).expandDims(2);\n",
        "        state.assign(state.mul(mask));\n",
        "      });\n",
        "    }\n",
        "\n",
        "    const plantSeed = (x, y)=>{\n",
        "      const x2 = w-x-seed.shape[2];\n",
        "      const y2 = h-y-seed.shape[1];\n",
        "      if (x<0 || x2<0 || y2<0 || y2<0)\n",
        "        return;\n",
        "      tf.tidy(()=>{\n",
        "        const a = seed.pad([[0, 0], [y, y2], [x, x2], [0,0]]);\n",
        "        state.assign(state.add(a));\n",
        "      });\n",
        "    }\n",
        "\n",
        "    const scale = 4;\n",
        "\n",
        "    const canvas = document.getElementById('canvas');\n",
        "    const ctx = canvas.getContext('2d');\n",
        "    canvas.width = w;\n",
        "    canvas.height = h;\n",
        "    canvas.style.width = `${w*scale}px`;\n",
        "    canvas.style.height = `${h*scale}px`;\n",
        "\n",
        "    canvas.onmousedown = e=>{\n",
        "      const x = Math.floor(e.clientX/scale);\n",
        "        const y = Math.floor(e.clientY/scale);\n",
        "        if (e.buttons == 1) {\n",
        "          if (e.shiftKey) {\n",
        "            plantSeed(x, y);\n",
        "          } else {\n",
        "            damage(x, y, 8);\n",
        "          }\n",
        "        }\n",
        "    }\n",
        "    canvas.onmousemove = e=>{\n",
        "      const x = Math.floor(e.clientX/scale);\n",
        "      const y = Math.floor(e.clientY/scale);\n",
        "      if (e.buttons == 1 && !e.shiftKey) {\n",
        "        damage(x, y, 8);\n",
        "      }\n",
        "    }\n",
        "\n",
        "    function step() {\n",
        "      tf.tidy(()=>{\n",
        "        state.assign(model.execute(\n",
        "            {x:state, fire_rate:tf.tensor(0.5),\n",
        "            angle:tf.tensor(0.0), step_size:tf.tensor(1.0)}, ['Identity']));\n",
        "      });\n",
        "    }\n",
        "\n",
        "    function render() {\n",
        "      step();\n",
        "\n",
        "      const imageData = tf.tidy(()=>{\n",
        "        const rgba = state.slice([0, 0, 0, 0], [-1, -1, -1, 4]);\n",
        "        const a = state.slice([0, 0, 0, 3], [-1, -1, -1, 1]);\n",
        "        const img = tf.tensor(1.0).sub(a).add(rgba).mul(255);\n",
        "        const rgbaBytes = new Uint8ClampedArray(img.dataSync());\n",
        "        return new ImageData(rgbaBytes, w, h);\n",
        "      });\n",
        "      ctx.putImageData(imageData, 0, 0);\n",
        "\n",
        "      requestAnimationFrame(render);\n",
        "    }\n",
        "    render();\n",
        "  }\n",
        "  run();\n",
        "\n",
        "</script>\n",
        "''')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POma99rMIfV4"
      },
      "source": [
        "#@title WebGL Demo\n",
        "\n",
        "#@markdown This code exports quantized models for the WebGL demo that is used in the article.\n",
        "#@markdown The demo code can be found at https://github.com/distillpub/post--growing-ca/blob/master/public/ca.js\n",
        "\n",
        "def pack_layer(weight, bias, outputType=np.uint8):\n",
        "  in_ch, out_ch = weight.shape\n",
        "  assert (in_ch%4==0) and (out_ch%4==0) and (bias.shape==(out_ch,))\n",
        "  weight_scale, bias_scale = 1.0, 1.0\n",
        "  if outputType == np.uint8:\n",
        "    weight_scale = 2.0*np.abs(weight).max()\n",
        "    bias_scale = 2.0*np.abs(bias).max()\n",
        "    weight = np.round((weight/weight_scale+0.5)*255)\n",
        "    bias = np.round((bias/bias_scale+0.5)*255)\n",
        "  packed = np.vstack([weight, bias[None,...]])\n",
        "  packed = packed.reshape(in_ch+1, out_ch//4, 4)\n",
        "  packed = outputType(packed)\n",
        "  packed_b64 = base64.b64encode(packed.tobytes()).decode('ascii')\n",
        "  return {'data_b64': packed_b64, 'in_ch': in_ch, 'out_ch': out_ch,\n",
        "          'weight_scale': weight_scale, 'bias_scale': bias_scale,\n",
        "          'type': outputType.__name__}\n",
        "\n",
        "def export_ca_to_webgl_demo(ca, outputType=np.uint8):\n",
        "  # reorder the first layer inputs to meet webgl demo perception layout\n",
        "  chn = ca.channel_n\n",
        "  w1 = ca.weights[0][0, 0].numpy()\n",
        "  w1 = w1.reshape(chn, 3, -1).transpose(1, 0, 2).reshape(3*chn, -1)\n",
        "  layers = [\n",
        "      pack_layer(w1, ca.weights[1].numpy(), outputType),\n",
        "      pack_layer(ca.weights[2][0, 0].numpy(), ca.weights[3].numpy(), outputType)\n",
        "  ]\n",
        "  return json.dumps(layers)\n",
        "\n",
        "with zipfile.ZipFile('webgl_models8.zip', 'w') as zf:\n",
        "  for e in EMOJI:\n",
        "    zf.writestr('ex1_%s.json'%e, export_ca_to_webgl_demo(get_model(e, use_pool=0, damage_n=0)))\n",
        "    run = 1 if e in '😀🕸' else 0  # select runs that happen to quantize better\n",
        "    zf.writestr('ex2_%s.json'%e, export_ca_to_webgl_demo(get_model(e, use_pool=1, damage_n=0, run=run)))\n",
        "    run = 1 if e in '🦎' else 0    # select runs that happen to quantize better\n",
        "    zf.writestr('ex3_%s.json'%e, export_ca_to_webgl_demo(get_model(e, use_pool=1, damage_n=3, run=run)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}